整个Internet是一张大的网络，通过使用爬虫自动化工具，爬取我们想要访问的web下面的数据。爬虫爬取数据基本有四/五个步骤流程。


# 1. 爬虫的基本流程

## 1.1 发起请求

通过HTTP库来向目标站点发起http请求，即是发送一个request，里面可以包含有header等信息，等待服务器响应。请求类型一般有`GET`和`POST`类型。

- GET请求：在URL中携带参数
- POST请求：需要构建表单，指定请求参数

在request的header里，可以指定`user-agent`, `host`, `cookie`, `language`, `encoding`等信息。

## 1.2 获取响应内容

如果服务器认为这是一个正常的请求，则会返回一个`response`给客户端，其内容就是该网页的内容，其类型可能是`HTML`, `JSON`字符串或者`二进制数据(图片视频等)`。

## 1.3 解析响应内容

- 如果返回内容为`HTML`内容，则使用一些库如`beautifulsoup`来解析获取需要的标签如`div`的值。
- 如果返回内容为`JSON`内容，可以直接转换为`JSON`对象来进行解析。
- 如果返回为`二进制`内容，可以做保存或者进一步处理。

## 1.4 保存数据

可以将解析后的数据保存到文本，Excel或者数据库，常见的方式为保存到如`MongoDB`和`Redis`这类非关系型的数据库中。

## 1.5 分析数据

对保存后的数据进行进一步的分析。

# 2. 观察HTTP/HTTPS访问过程

使用Chrome/Firefox浏览器打开网址，右键点击`检查`即可进入网页元素查看模式，选择`Network`页，会发现在 `Network` 页面的下方出现了一个个的条目，那么这一个条目就代表一次发送 **Request** 和接收 **Response** 的过程，如下图。

![](http://ww1.sinaimg.cn/large/67c0b572gy1ftjimg59gej20yv0hswj8.jpg)



每条记录都分别有`Name`,`Status`,`Type`,`Initiator`,`Size`, `Time`和`Waterfall`,分别表示：

- Name：即 Request 的名称。一般会用URL的最后一部分内容当做名称。
- Status：即 Response 的状态码。这里显示为 200，代表 Response 是正常的，通过状态码我们可以判断发送了 Request 之后是否得到了正常的 Response。
- Type：即 Request 请求的文档类型。这里为 document，代表我们这次请求的是一个 HTML 文档，内容就是一些 HTML 代码。
- Initiator：即请求源。用来标记 Request 是由哪个对象或进程发起的。
- Size：即从服务器下载的文件和请求的资源大小。如果是从缓存中取得的资源则该列会显示 from cache。
- Time：即发起 Request 到获取到 Response 所用的总时间。
- Waterfall：即网络请求的可视化瀑布流。

单机每个请求，在右侧可以看到`header`,`preview`,`Response`,`Cookies`和`Timing`.其中`Response`是服务器返回数据，浏览器渲染这些数据显示成我们可见的样式。

![](http://ww1.sinaimg.cn/large/67c0b572gy1ftjio56ygkj211p0ijdm9.jpg)



注：在`ALL`旁边有`XHR`标签页，这个表示的是`XMLHttpRequest` 对象，`Jquery`中的`Ajax`就是对 `XHR`的封装。
